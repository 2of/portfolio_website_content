
    {
        "name": "geolocate1",
        "title": "Machine Learning for Neighbourhood-Scale GeoLocalization of Street Level Imagery from Local Image Features",
        "subtitle": "Leveraging object detection, text embeddings, and colour profiling for geographic coordinate prediction.",
        "heroImage" :  "/assets/heroImages/geo.png",
       
        "heroLinks": [
          {
            "title" : "Medium",
            "type" : "Article",
            "to" :  "/404"
          },{
            "title" : "Github",
            "type" : "Code",
            "to" :  "/404"
          },{
            "title" : "Thesis",
            "type" : "Academic",
            "to" :  "/404"
          }
          ,{
            "title" : "Video",
            "type" : "Video",
            "to" :  "/404"
          }
        ],
        "sections": [
          {
            "name": "A Brief Overview",
            "type": "text",
            "boost": true,
            "items": [
              {
                "type": "paragraph",
                "text": "Street level imagery is everywhere. Humans are kinda.. street - level sized afterall. Services such as Google Maps and Mapillary make are a particularly useful repository for obtaining street level imagery. "
              },
              
              {"type": "paragraph",
              "text":"Our goal, here, was to construct a Neural network based Machine Learning model, which if given an unseen street level image, can somewhat accurately predict its location at some scale. Here, we chose a 20km^2 area in Chicago and achieved about a 1.3km accuracy as an aggregate score across 3 discrete models. "
              },{
                "type": "image",
                "src": "assets/images/geo/preds.png",
                "alt": "Introductory Prediction Heatmap"
              },

              {"type":"paragraph",
            "text":"A key underpinning idea is defining which features should inform the model(s). We chose an explicit approach in lieu of implicitly learning GeoLocators. We explicitly trained models to detect local image features such as signage, park benches, traffic lights, pedestrian crossings and so on. These inform feature vectors per image. We additionally extract text from the scene and the images and use a higher dimensional embedding as an associative (feature) informer for the model. Combining all of these together, and pumping it through a clustering K-means algorithm, we can usefully average the output to determine GeoLocalization."
          },
               
              {
                "type": "image",
                "src": "assets/images/geo/model.png",
                "alt": "Aerial View of the Machine Learning Model(s) and psuedo-ensemble"
              },

              {"type":"paragraph",
            "text" : "The whole she-bang is written in python and JS, using tensor flow and Keras and a bunch of industry standards. Very crucially it was trained over 6 or so hours (for 50 epochs, but the model had converged after about 30 on our limited selection of hyper parameters, as it was just a summer project) on a single, Bedroom-friendly GPU."
          },
              {
                "type": "paragraph",
                "text": "This Project designs and implements a method for Neighbourhood scale Geolocalization for Street Level Imagery using Machine Learning and Deep Learning Methods and explores in great depth the performance and learning of these methods"
              },
              
              
              {
                "type": "pills",
                "pills": ["Machine Learning", "AI", "Deep Learning", "Multi-Scale Prediction", "Fine Tuning / Transfer Learning","Large Data Processing", "Neural Network Design", "Neural Network Performance Analysis", "Scalable Neural Network Design", "Python3", "Tensorflow", "Keras", ".... etc" ]
              },
              
              {
                "type":"link",
                "to" :"/404",
                "label" :"GitHub Repository"
              },{
                "type":"link",
                "to" :"/404",
                "label" :"Thesis"
              }              
            ]
          },
          {
            "name": "Methodology",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "The proposed method heavily uses transfer learning for both object detection and text processing. A fine-tuned YOLOv11 model is used to detect GeoInformers, such as signage, crosswalks, and traffic lights, which serve as crucial geo-informative features."
              },
              {
                "type": "highlight",
                "text": "Transfer learning is applied to adapt the YOLOv11 model to detect new classes of objects, providing high efficiency with smaller datasets."
              },

              
                {
                  "type": "paragraph",
                  "text": "This research integrates object detection as a preprocessing step for geolocation, utilizing YOLOv11 with a ResNet100 backbone. Transfer learning was employed to fine-tune models for detecting domain-specific GeoInformers such as signage, streetlights, and crosswalks, which serve as explicit spatial indicators."
                },
                {
                  "type": "paragraph",
                  "text": "Fine-tuned YOLO models were trained to detect geo-informative objects beyond the standard COCO classes, enabling more targeted feature extraction. The crosswalk and signage models demonstrated high detection accuracy, achieving mAP50 scores of approximately 0.986, while the streetlight model exhibited a comparatively lower mAP50 of 0.906."
                },

                {
                  "type": "image",
                  "src": "/assets/images/geo/YOLO.png",
                  "alt": "Samples of signage from the transfer learned models"
                },
   
              {
                "type": "paragraph",
                "text": "Additionally, text extracted from street signage is processed using the SBERT all-MiniLM-L6-v2 model to convert the raw OCR output into dense embeddings, capturing the semantic meaning of the words and their geographical context."
              },
              {
                "type": "highlight",
                "text": "Key advantage: The SBERT model is chosen for its ability to capture contextual relationships between geographical terms and provide compact embeddings that integrate well with other features."
              },
              {
                "type": "image",
                "src": "/assets/images/model_diagram.png",
                "alt": "Diagram showing the integration of YOLO, SBERT, and colour histograms into the geolocalisation model."
              }
            ]
          },
          {
            "name": "Challenges Encountered",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Throughout the research, several challenges were encountered. One of the main difficulties was overfitting, where the full-image model learned to predict locations in densely sampled areas rather than generalizable features."
              },
              {
                "type": "highlight",
                "text": "Overfitting became evident when predictions were biased toward densely populated regions, undermining the model's ability to generalize to more sparsely represented areas."
              },
              {
                "type": "paragraph",
                "text": "Another challenge was the insufficient separability of concatenated object and text embeddings, which hindered effective clustering and geo-location grouping."
              },
              {
                "type": "highlight",
                "text": "A lack of clear distinctions between detected objects and extracted text in the embeddings led to difficulties when attempting to use K-means clustering."
              },
              {
                "type": "pills",
                "pills": ["Overfitting", "Clustering Issues", "Data Imbalances", "Attention Mechanisms"]
              }
            ]
          },
          {
            "name": "Data and Datasets",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Data is procured from Mapillary and Google Maps, we bind the area to 20km^2 about Chicago due tot the diversity of GeoInformative features and also the availability of imagery"
              },
              {
                "type": "highlight",
                "text": "The entire dataset reaches 150k images over about 30gb"
              },
              {
                "type": "image",
                "src": "/assets/images/geo/sampleImages.png",
                "alt": "Diagram showing the integration of YOLO, SBERT, and colour histograms into the geolocalisation model."
              },
              {
                "type": "paragraph",
                "text": "The model was trained using two primary datasets: the Overall Image Embeddings Dataset (151,510 records) and the Signage Dataset (381,234 records), both derived from Mapillary API and Google Street View."
              },
              {
                "type": "highlight",
                "text": "Key insight: The data from Mapillary was essential in providing a variety of street-level images, but data density imbalances presented challenges in learning generalizable features."
              },
              {
                "type": "image",
                "src": "/assets/images/dataset_distribution.png",
                "alt": "Distribution of data across different areas within the Chicago region."
              },
              {
                "type": "paragraph",
                "text": "Images were processed to extract object detections, text embeddings, and colour histograms, which were then used as input for the machine learning models."
              }
            ]
          },
          {
            "name": "Transfer Learning and Pretrained Models",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Transfer learning played a key role in this research. The pre-trained YOLOv11 model with a ResNet100 backbone provided a strong base for detecting geo-informative objects."
              },
              {
                "type": "highlight",
                "text": "Transfer learning enabled the YOLOv11 model to be adapted to detect specific objects like signage, which would have been difficult with small custom datasets."
              },
              {
                "type": "paragraph",
                "text": "For text processing, SBERT was used to generate semantic embeddings of the extracted text, allowing for better handling of geographical terms and improving the overall geolocalisation process."
              },
              {
                "type": "highlight",
                "text": "The use of pretrained embeddings for both text and objects reduced the need for extensive retraining, allowing the model to focus on the more complex aspects of geolocalisation."
              }
            ]
          },
          {
            "name": "Attention Mechanisms and Results",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Attention mechanisms were integrated into the CNN and Multi-Dense Network models to help focus on the most geo-informative parts of the input features."
              },
              {
                "type": "highlight",
                "text": "However, the attention mechanisms did not always yield positive results, as they sometimes introduced noise and exacerbated the overfitting problem, particularly in dense areas."
              },
              {
                "type": "paragraph",
                "text": "Despite the challenges with attention, the models showed promise in reducing mean squared error (MSE), though predictions remained concentrated in high-density regions."
              },
              {
                "type": "image",
                "src": "/assets/images/attention_results.png",
                "alt": "Results showing the impact of attention mechanisms on geolocalisation performance."
              }
            ]
          },
          {
            "name": "Future Work",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Several avenues for improvement have been identified, such as addressing data density issues through subsampling or incorporating multiple datasets to improve model generalization."
              },
              {
                "type": "highlight",
                "text": "Future work will focus on exploring alternative geolocalisation approaches, like GeoCells, and refining clustering techniques to better handle the geo-informative features from text, objects, and colour histograms."
              },
              {
                "type": "paragraph",
                "text": "Additionally, the model could benefit from sequences of images, similar to LSTM networks, to capture spatial relationships and reduce the impact of variations in viewpoint."
              },
              {
                "type": "pills",
                "pills": ["Data Augmentation", "GeoCells", "Clustering", "LSTM Networks"]
              }
            ]
          }
        ],
        "link": {
          "text": "Read More About This Geolocalisation Method",
          "url": "https://example.com/geolocalisation-method"
        }

    }
     